{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volltexte scrapen\n",
    "\n",
    "### FAZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# ich versteh nicht, warum wir hier faz_dir als data_dir genommen haben, wenn wir die allgemeine data_dir doch für die anderen Extraktionen brauchen\n",
    "data_dir = \"../data/faz/raw-full-articles/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/faz/all-articles.json\", \"r\") as file:\n",
    "    faz = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz = [article for article in faz if (\"jemen\" in article[\"title\"].lower()) or (\"jemen\" in article[\"surtitle\"].lower())]\n",
    "\n",
    "# für jeden link in der liste links wird die schleife einmal ausgeführt, danach für 3 sek pausiert, weil wir menschen sind\n",
    "for article in faz: \n",
    "    # der link wird beim server angefragt und der text der antwort in ein html dokument geschrieben, das im richtigen ordner abgespeichert wird\n",
    "    response = requests.get(article[\"link\"]).text\n",
    "    id = article[\"link\"].split(\"uid=\")[1]\n",
    "    filename = data_dir + id + \".html\"\n",
    "    article[\"id\"] = id\n",
    "    with open(filename, \"w\") as file:\n",
    "        file.write(response)\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZEIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/zeit/all-articles.json\", \"r\") as file:\n",
    "    zeit = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeit = [article for article in zeit if (\"jemen\" in article[\"title\"].lower()) or (\"jemen\" in article[\"surtitle\"].lower())]\n",
    "\n",
    "# für jeden link in der liste links wird die schleife einmal ausgeführt, danach für 3 sek pausiert, weil wir menschen sind\n",
    "for article in zeit: \n",
    "    # der link wird beim server angefragt und der text der antwort in ein html dokument geschrieben, das im richtigen ordner abgespeichert wird\n",
    "    response = requests.get(article[\"link\"]).text\n",
    "    id = article[\"link\"].split(\"document/\")[1].split(\"/\")[0]\n",
    "    filename = \"../data/zeit/raw-full-articles/\" + id + \".html\"\n",
    "    article[\"id\"] = id\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(response)\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/sz/all-articles.json\", \"r\") as file:\n",
    "    sz = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = [article for article in sz if (\"jemen\" in article[\"title\"].lower()) or (\"jemen\" in article[\"surtitle\"].lower())]\n",
    "\n",
    "# für jeden link in der liste links wird die schleife einmal ausgeführt, danach für 3 sek pausiert, weil wir menschen sind\n",
    "for article in sz: \n",
    "    # der link wird beim server angefragt und der text der antwort in ein html dokument geschrieben, das im richtigen ordner abgespeichert wird\n",
    "    response = requests.get(article[\"link\"]).text\n",
    "    id = article[\"link\"].split(\"Id=\")[1]\n",
    "    filename = \"../data/sz/raw-full-articles/\" + id + \".html\"\n",
    "    article[\"id\"] = id\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(response)\n",
    "    time.sleep(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('jemen-scraper')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c05e784c37b7486e763435563ea73fc5884b3661493573245e31e915d866c156"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
